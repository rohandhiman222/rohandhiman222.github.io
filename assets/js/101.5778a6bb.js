(window.webpackJsonp=window.webpackJsonp||[]).push([[101],{383:function(e,r,s){"use strict";s.r(r);var a=s(14),t=Object(a.a)({},(function(){var e=this,r=e._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"node-js-cluster-and-worker-threads"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#node-js-cluster-and-worker-threads"}},[e._v("#")]),e._v(" Node.js Cluster and Worker Threads")]),e._v(" "),r("h2",{attrs:{id:"node-js-cluster"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#node-js-cluster"}},[e._v("#")]),e._v(" Node.js Cluster")]),e._v(" "),r("h3",{attrs:{id:"overview"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),r("p",[e._v("The Cluster module in Node.js is designed to allow the creation of child processes (workers) that can share the same server port. This is particularly useful for maximizing the utilization of multi-core systems and handling more concurrent operations. The master process is responsible for managing these worker processes.")]),e._v(" "),r("h3",{attrs:{id:"why-use-cluster"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#why-use-cluster"}},[e._v("#")]),e._v(" Why Use Cluster?")]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Maximizing CPU Utilization:")])]),e._v(" "),r("ul",[r("li",[e._v("JavaScript runs on a single thread in Node.js. By default, a Node.js application can only use one CPU core. Clustering allows you to fork multiple processes, each utilizing a separate core, which maximizes the CPU usage.")]),e._v(" "),r("li",[e._v("Example: A server running on an 8-core machine can fork 8 worker processes, each handling requests independently, thus utilizing all 8 cores efficiently.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Improved Performance:")])]),e._v(" "),r("ul",[r("li",[e._v("By distributing incoming requests among multiple worker processes, clustering can handle more requests concurrently, improving the overall throughput and performance.")]),e._v(" "),r("li",[e._v("Example: A high-traffic website can distribute HTTP requests across multiple workers, ensuring the server remains responsive even under heavy load.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Failover and Resilience:")])]),e._v(" "),r("ul",[r("li",[e._v("If a worker process crashes, the master process can detect this and start a new worker process. This provides fault tolerance and resilience, ensuring that the application remains available.")]),e._v(" "),r("li",[e._v("Example: In a payment processing system, if one worker handling transactions crashes, the master can spawn a new worker to take over, preventing downtime.")])])])]),e._v(" "),r("h3",{attrs:{id:"where-to-use-cluster"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#where-to-use-cluster"}},[e._v("#")]),e._v(" Where to Use Cluster?")]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Web Servers:")])]),e._v(" "),r("ul",[r("li",[e._v("Web servers handling a large number of simultaneous connections benefit from clustering, as it allows them to handle more requests efficiently.")]),e._v(" "),r("li",[e._v("Example: An online store with heavy traffic can use clustering to handle multiple simultaneous customer requests.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("API Gateways:")])]),e._v(" "),r("ul",[r("li",[e._v("API gateways that need to process numerous incoming API requests can distribute the load among multiple worker processes.")]),e._v(" "),r("li",[e._v("Example: A backend service that aggregates data from multiple APIs can use clustering to manage the high volume of incoming requests.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Microservices:")])]),e._v(" "),r("ul",[r("li",[e._v("Deploying microservices that need to scale across multiple CPU cores can benefit from clustering, ensuring each microservice can handle its share of the load.")]),e._v(" "),r("li",[e._v("Example: A microservice architecture with individual services for user authentication, data processing, and notifications can use clustering for each service to scale effectively.")])])])]),e._v(" "),r("h3",{attrs:{id:"example-implementation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#example-implementation"}},[e._v("#")]),e._v(" Example Implementation")]),e._v(" "),r("p",[e._v("Create a "),r("code",[e._v("cluster.js")]),e._v(" file:")]),e._v(" "),r("p",[e._v("```javascript\nconst cluster = require('cluster');\nconst http = require('http');\nconst numCPUs = require('os').cpus().length;")]),e._v(" "),r("p",[e._v("if (cluster.isMaster) {\nconsole.log(`Master ${process.pid} is running`);")]),e._v(" "),r("p",[e._v("// Fork workers.\nfor (let i = 0; i < numCPUs; i++) {\ncluster.fork();\n}")]),e._v(" "),r("p",[e._v("cluster.on('exit', (worker, code, signal) => {\nconsole.log(`Worker ${worker.process.pid} died`);\n// Fork a new worker if one dies\ncluster.fork();\n});\n} else {\n// Workers can share any TCP connection.\n// In this case, it is an HTTP server.\nhttp.createServer((req, res) => {\nres.writeHead(200);\nres.end('Hello World\n');\n}).listen(8000);")]),e._v(" "),r("p",[e._v("console.log(`Worker ${process.pid} started`);\n}\n```")]),e._v(" "),r("p",[r("strong",[e._v("Detailed Steps:")])]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Master Process:")])]),e._v(" "),r("ul",[r("li",[e._v("Checks if the current process is the master using `cluster.isMaster`.")]),e._v(" "),r("li",[e._v("If it is, forks worker processes equal to the number of CPU cores using `cluster.fork()`.")]),e._v(" "),r("li",[e._v("Listens for worker exit events and forks new workers if any die.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Worker Process:")])]),e._v(" "),r("ul",[r("li",[e._v("Each worker runs an HTTP server on the same port (8000 in this example).")]),e._v(" "),r("li",[e._v("Handles incoming requests independently.")])])])]),e._v(" "),r("h2",{attrs:{id:"node-js-worker-threads"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#node-js-worker-threads"}},[e._v("#")]),e._v(" Node.js Worker Threads")]),e._v(" "),r("h3",{attrs:{id:"overview-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#overview-2"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),r("p",[e._v("The Worker Threads module in Node.js provides a way to run JavaScript code in parallel threads. Each worker thread runs in its own isolated context, allowing true parallel execution, which is ideal for CPU-intensive tasks that would otherwise block the event loop.")]),e._v(" "),r("h3",{attrs:{id:"why-use-worker-threads"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#why-use-worker-threads"}},[e._v("#")]),e._v(" Why Use Worker Threads?")]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("True Parallelism:")])]),e._v(" "),r("ul",[r("li",[e._v("Worker threads provide true parallel execution, making them ideal for CPU-bound tasks that require heavy computations.")]),e._v(" "),r("li",[e._v("Example: A mathematical computation task, such as calculating prime numbers, can run in parallel threads, reducing the overall execution time.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Isolated Memory:")])]),e._v(" "),r("ul",[r("li",[e._v("Each worker thread has its own isolated memory space, preventing memory leaks in one thread from affecting others.")]),e._v(" "),r("li",[e._v("Example: An image processing application where each thread processes a separate image, ensuring that memory leaks in one thread do not impact the entire application.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Offloading CPU-Intensive Tasks:")])]),e._v(" "),r("ul",[r("li",[e._v("By offloading heavy computations to worker threads, the main thread remains responsive for handling I/O operations.")]),e._v(" "),r("li",[e._v("Example: A server that handles real-time user interactions can offload data processing tasks to worker threads, ensuring the main thread remains responsive.")])])])]),e._v(" "),r("h3",{attrs:{id:"where-to-use-worker-threads"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#where-to-use-worker-threads"}},[e._v("#")]),e._v(" Where to Use Worker Threads?")]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Heavy Computation:")])]),e._v(" "),r("ul",[r("li",[e._v("Tasks requiring intensive CPU usage, such as data processing, image manipulation, or scientific computations.")]),e._v(" "),r("li",[e._v("Example: A data analysis tool that processes large datasets in parallel threads, speeding up the analysis.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Background Tasks:")])]),e._v(" "),r("ul",[r("li",[e._v("Running tasks in the background without blocking the main thread, such as scheduled jobs or background processing.")]),e._v(" "),r("li",[e._v("Example: A background job that periodically aggregates and processes data from various sources.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Concurrent Tasks:")])]),e._v(" "),r("ul",[r("li",[e._v("Running multiple tasks concurrently that can be executed in parallel.")]),e._v(" "),r("li",[e._v("Example: A video processing application where each thread processes a different video segment simultaneously.")])])])]),e._v(" "),r("h3",{attrs:{id:"example-implementation-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#example-implementation-2"}},[e._v("#")]),e._v(" Example Implementation")]),e._v(" "),r("p",[e._v("Create a "),r("code",[e._v("worker_threads.js")]),e._v(" file:")]),e._v(" "),r("p",[e._v("```javascript\nconst { Worker, isMainThread, parentPort, workerData } = require('worker_threads');")]),e._v(" "),r("p",[e._v("if (isMainThread) {\nconsole.log(`Main thread: ${process.pid}`);")]),e._v(" "),r("p",[e._v("// Create a new worker thread.\nconst worker = new Worker(__filename, {\nworkerData: { start: 1, end: 100000000 }\n});")]),e._v(" "),r("p",[e._v("worker.on('message', (message) => {\nconsole.log(`Received message from worker: ${message}`);\n});")]),e._v(" "),r("p",[e._v("worker.on('exit', (code) => {\nconsole.log(`Worker exited with code ${code}`);\n});\n} else {\nconst { start, end } = workerData;\nlet sum = 0;")]),e._v(" "),r("p",[e._v("for (let i = start; i <= end; i++) {\nsum += i;\n}")]),e._v(" "),r("p",[e._v("// Send the result back to the main thread.\nparentPort.postMessage(sum);\n}\n```")]),e._v(" "),r("p",[r("strong",[e._v("Detailed Steps:")])]),e._v(" "),r("ol",[r("li",[r("p",[r("strong",[e._v("Main Thread:")])]),e._v(" "),r("ul",[r("li",[e._v("Checks if the current thread is the main thread using `isMainThread`.")]),e._v(" "),r("li",[e._v("If it is, creates a new worker thread using the `Worker` class, passing the current file (`__filename`) and initial data (`workerData`).")]),e._v(" "),r("li",[e._v("Listens for messages from the worker and handles worker exit events.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Worker Thread:")])]),e._v(" "),r("ul",[r("li",[e._v("Receives initial data (`workerData`) containing the range of numbers to sum.")]),e._v(" "),r("li",[e._v("Calculates the sum of numbers from `start` to `end`.")]),e._v(" "),r("li",[e._v("Sends the result back to the main thread using `parentPort.postMessage`.")])])])]),e._v(" "),r("h2",{attrs:{id:"summary"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#summary"}},[e._v("#")]),e._v(" Summary")]),e._v(" "),r("h3",{attrs:{id:"cluster"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#cluster"}},[e._v("#")]),e._v(" Cluster:")]),e._v(" "),r("p",[r("strong",[e._v("Pros:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Easy to Scale:")]),e._v(" Can handle many concurrent connections by forking multiple worker processes.")]),e._v(" "),r("li",[r("strong",[e._v("Load Balancing:")]),e._v(" Distributes incoming requests among multiple workers, preventing any single process from being overwhelmed.")]),e._v(" "),r("li",[r("strong",[e._v("Fault Tolerance:")]),e._v(" If a worker crashes, the master process can automatically spawn a new one, ensuring continuous availability.")])]),e._v(" "),r("p",[r("strong",[e._v("Cons:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Shared Memory Issues:")]),e._v(" Workers share memory space, which can lead to memory leaks affecting all workers.")]),e._v(" "),r("li",[r("strong",[e._v("IPC Overhead:")]),e._v(" Inter-Process Communication (IPC) can introduce overhead, especially with high communication needs.")])]),e._v(" "),r("h3",{attrs:{id:"worker-threads"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#worker-threads"}},[e._v("#")]),e._v(" Worker Threads:")]),e._v(" "),r("p",[r("strong",[e._v("Pros:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("True Parallelism:")]),e._v(" Provides true parallel execution, ideal for CPU-bound tasks.")]),e._v(" "),r("li",[r("strong",[e._v("Isolated Memory:")]),e._v(" Each worker thread has its own isolated memory space, reducing the risk of memory leaks affecting other threads.")]),e._v(" "),r("li",[r("strong",[e._v("Offloads Heavy Computations:")]),e._v(" Keeps the main thread responsive by offloading CPU-intensive tasks.")])]),e._v(" "),r("p",[r("strong",[e._v("Cons:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Complex Management:")]),e._v(" More complex to manage compared to clustering.")]),e._v(" "),r("li",[r("strong",[e._v("Higher Overhead:")]),e._v(" Creating and managing threads can introduce higher overhead compared to simple asynchronous tasks.")])]),e._v(" "),r("h3",{attrs:{id:"use-cases"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#use-cases"}},[e._v("#")]),e._v(" Use Cases:")]),e._v(" "),r("ul",[r("li",[r("p",[r("strong",[e._v("Cluster:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Web Servers:")]),e._v(" Handling many simultaneous connections.")]),e._v(" "),r("li",[r("strong",[e._v("API Gateways:")]),e._v(" Processing numerous incoming API requests.")]),e._v(" "),r("li",[r("strong",[e._v("Microservices:")]),e._v(" Scaling individual services across multiple CPU cores.")])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("Worker Threads:")])]),e._v(" "),r("ul",[r("li",[r("strong",[e._v("Heavy Computation:")]),e._v(" Data processing, image manipulation, scientific computations.")]),e._v(" "),r("li",[r("strong",[e._v("Background Tasks:")]),e._v(" Scheduled jobs, background processing.")]),e._v(" "),r("li",[r("strong",[e._v("Concurrent Tasks:")]),e._v(" Running multiple tasks concurrently in parallel threads.")])])])]),e._v(" "),r("p",[e._v("By understanding these methods and their appropriate use cases, you can optimize your Node.js applications for both performance and scalability, ensuring they run efficiently on modern multi-core systems.")])])}),[],!1,null,null,null);r.default=t.exports}}]);